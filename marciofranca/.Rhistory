filter(!is.na(hashtags)) %>%
mutate(hashtags = toupper(hashtags))
tweets %>%
unnest(hashtags) %>%
filter(!is.na(hashtags)) %>%
mutate(hashtags = toupper(hashtags)) %>%
group_by(hashtags) %>%
summarise(total = n())
tweets %>%
unnest(hashtags) %>%
filter(!is.na(hashtags)) %>%
mutate(hashtags = toupper(hashtags))
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count/followers_count),
favPerFollower = sum(favourites_count/followers_count)) %>%
ggplot(aes(x = timeline, y = retweets, fill = timeline))+
geom_bar(stat="identity")
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count/followers_count),
favPerFollower = sum(favourites_count/followers_count)) %>%
ggplot(aes(x = timeline, y = favorites, fill = timeline))+
geom_bar(stat="identity")
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count/followers_count),
favPerFollower = sum(favourites_count/followers_count)) %>%
ggplot(aes(x = timeline, y = retPerFollower, fill = timeline))+
geom_bar(stat="identity")
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count/followers_count),
favPerFollower = sum(favourites_count/followers_count)) %>%
ggplot(aes(x = timeline, y = favPerFollower, fill = timeline))+
geom_bar(stat="identity")
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count)/followers_count,
favPerFollower = sum(favourites_count)/followers_count,
interactionPerFollower = sum(favourites_count+retweet_count)/followers_count) %>%
ggplot(aes(x = timeline, y = favPerFollower, fill = timeline))+
geom_bar(stat="identity")
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count)/mean(followers_count),
favPerFollower = sum(favourites_count)/mean(followers_count),
interactionPerFollower = sum(favourites_count+retweet_count)/mean(followers_count)) %>%
ggplot(aes(x = timeline, y = favPerFollower, fill = timeline))+
geom_bar(stat="identity")
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count/followers_count),
favPerFollower = sum(favourites_count/followers_count),
interactionPerFollower = sum((favourites_count+retweet_count)/followers_count)) %>%
ggplot(aes(x = timeline, y = favPerFollower, fill = timeline))+
geom_bar(stat="identity")
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count/followers_count),
favPerFollower = sum(favourites_count/followers_count),
interactionPerFollower = sum((favourites_count+retweet_count)/followers_count)) %>%
ggplot(aes(x = timeline, y = retweets, fill = timeline))+
geom_bar(stat="identity")
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count/followers_count),
favPerFollower = sum(favourites_count/followers_count),
interactionPerFollower = sum((favourites_count+retweet_count)/followers_count)) %>%
ggplot(aes(x = timeline, y = favorites, fill = timeline))+
geom_bar(stat="identity")
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count/followers_count),
favPerFollower = sum(favourites_count/followers_count),
interactionPerFollower = sum((favourites_count+retweet_count)/followers_count)) %>%
ggplot(aes(x = timeline, y = retPerFollower, fill = timeline))+
geom_bar(stat="identity")
tweets %>%
group_by(timeline) %>%
summarise(retweets = sum(retweet_count),
favorites = sum(favourites_count),
retPerFollower = sum(retweet_count/followers_count),
favPerFollower = sum(favourites_count/followers_count),
interactionPerFollower = sum((favourites_count+retweet_count)/followers_count)) %>%
ggplot(aes(x = timeline, y = favPerFollower, fill = timeline))+
geom_bar(stat="identity")
shiny::runApp('RScript/culturismo')
install.packages("shinySignals")
devtools::install_github("hadley/shinySignals")
runApp('RScript/culturismo')
intall.packages("quanteda")
install.packages("quanteda")
runApp('RScript/culturismo')
install.packages("readtext")
runApp('RScript/culturismo')
install.packages("shinydashboard")
runApp('RScript/culturismo')
install.packages("shinyFiles")
runApp('RScript/culturismo')
install.packages("stylo")
runApp('RScript/culturismo')
install.packages("bit")
runApp('RScript/culturismo')
runApp('RScript/culturismo')
runApp('RScript/culturismo')
workdir <- "/Users/isiscosta/RScript/culturismo"
database <- read_xlsx(file.path(workdir,"data/database.xlsx"))
as.character(database$cidade)
as.character(database$cidade)[10]
as.character(database$cidade)[13]
as.character(database$cidade)[14]
destination <- as.character(database$cidade)[14]
Destination <- as.character(database$cidade)[14]
allcidades <- Destination
mycidades <- database %>% filter(cidade %in% allcidades) %>% select(cidade)
mypaises <- database %>% filter(cidade %in% allcidades) %>% select(país)
mylocais <- database %>% filter(cidade %in% allcidades) %>% select(local)
mylocais
mypaises
mycidades
install.packages("electionsBR")
library(electionsBR)
votos_2018 <- electionsBR::details_mun_zone_fed(2018)
library(tidyverse)
glimpse(votos_2018)
detalhes_2018 <- votos_2018
View(detalhes_2018)
pesquisas_2018 <- electionsBR::party_mun_zone_fed(2018)
glimpse(pesquisas_2018)
afiliacao_eleitores <- electionsBR::voter_affiliation(party = "PT")
afiliacao_eleitores <- electionsBR::voter_affiliation(party = "PT", uf="BA")
glimpse(afiliacao_eleitores)
View(afiliacao_eleitores)
save(afiliacao_eleitores, perfil_eleitores, pesquisas_2018, file="dados_eleicoes.RDat")
save(detalhes_2018, afiliacao_eleitores, perfil_eleitores, pesquisas_2018, file="dados_eleicoes.RDat")
save(detalhes_2018, afiliacao_eleitores, pesquisas_2018, file="dados_eleicoes.RDat")
library(tabulizer)
library(dplyr)
library(readr)
library(tidyverse)
setwd("/Users/isiscosta/RScript/Scite")
filenames <- c("FOS_003_18_16.pdf","FOS_007_878ed827-e2ff-002a-b31b-7f50eb50bb12.pdf","FOS_008_22735.pdf","FOS_009_1342-1349.pdf")
filename <- filenames[1]
?extract_metadata
extract_metadata(filename)
?extract_tables
df <- extract_tables(filename, output = "data.frame")
head(df)
View(df)
class(df)
head(df[1])
head(df[2])
head(df[[1]])
head(df[[2]])
filename
texts <- extract_text(filename)
class(texts)
texts
length(texts)
class(texts)
texts[1]
texts[[1]]
texts
stringr::str_detect(texts, pattern = "Table")
stringr::str_detect_all(texts, pattern = "Table")
stringr::str_extract_all(texts, pattern = "Table")
tabulizer::extract_tables(filename, output = "csv",outdir = getwd())
filenames <- c("FOS_003_18_16.pdf","FOS_007_878ed827-e2ff-002a-b31b-7f50eb50bb12.pdf","FOS_008_22735.pdf","FOS_009_1342-1349.pdf")
for(filename in filenames){
tabulizer::extract_tables(filename, output = "csv",outdir = getwd())
}
for(filename in filenames){
tabulizer::extract_tables(filename, output = "csv",outdir = getwd())
}
filenames <- c("FOS_003_18_16.pdf","FOS_007_87812.pdf","FOS_008_22735.pdf","FOS_009_1342-1349.pdf")
for(filename in filenames){
tabulizer::extract_tables(filename, output = "csv",outdir = getwd())
}
library(tidyverse)
library(lubridate)
dat <- readRDS("data/tweets_MF.rds")
setwd("/Users/isiscosta/RScript/marciofranca/")
dat <- readRDS("data/tweets_MF.rds")
install.packages("gTrendsR")
install.packages("gtrendsR")
library(gtrendsR)
?gtrends
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "today 12-m",
hl = "pt-br",
low_search_volume = TRUE,
tz = -120)
language_codes$code
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "today 12-m",
hl = "pt",
low_search_volume = TRUE,
tz = -120)
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "today 12-m",
hl = "pt",
low_search_volume = TRUE)
class(trendsMF)
names(trendsMF)
trendsMF$interest_by_city
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "today 12-m",
hl = "pt")
trendsMF
data("categories")
categories
categories[grepl("^Politics")]
categories[grepl("^Politics"),]
categories[grepl("^Politics",categories$name),]
categories[grepl("^Sport", categories$name), ]
categories[grepl("^Politics",categories$name),]
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "today 12-m",
hl = "pt",
category = 396)
trendsMF
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "all",
hl = "pt",
category = 396)
trendsMF
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "today 1-m",
hl = "pt",
category = 396)
trendsMF
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "today 3-m",
hl = "pt",
category = 396)
trendsMF
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "today 12-m",
hl = "pt",
category = 396)
trendsMF
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "2019-01-01 2020-03-01",
hl = "pt",
category = 396)
trendsMF
trendsMF <- gtrends("Márcio França",
geo = "BR",
time = "2019-01-01 2020-03-01",
category = 396,
onlyInterest = FALSE)
trendsMF
setwd("/Users/isiscosta/RScript/marciofranca/")
dat <- readRDS("data/tweets_MF.rds")
dat <- dat %>% mutate(data = round_date(ymd_hms(created_at),"day"))
View(dat)
datSP <- readRDS("data/tweets_SP.rds")
datSP <- datSP %>%
mutate(data = round_date(ymd_hms(created_at),"day"))
View(datSP)
datSP %>% count(retweet_location)
datSP %>% count(retweet_location) %>% arrange(n) %>% tail(20)
datSP %>% count(location) %>% arrange(n) %>% tail(20)
datSP <- datSP %>%
filter(
location %in% c("São Paulo, Brasil","São Paulo", "Sao Paulo, Brazil", "Taubaté, São Paulo"
)
)
datSP <- datSP %>%
mutate(data = round_date(ymd_hms(created_at),"day"))
View(datSP)
datSP %>% count(user_id)
datSP %>% count(user_id) %>% arrange(n)
datSP %>% count(user_id) %>% arrange(n) %>% tail(10)
datSP %>% count(user_id) %>% arrange(n) %>% tail(20)
datSP %>% count(screen_name) %>% arrange(n) %>% tail(20)
#########
library(dplyr)
library(tidytext)
install.packages("tidytext")
library(tidytext)
View(datSP)
## networks
datSP %>% select(text) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
## networks
datSP %>% select(text) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 4)
## networks
stopwords::stopwords(language = "pt")
## networks
badwords <- stopwords::stopwords(language = "pt")
datSP %>% filter(!text %in% badwords) %>%
select(text) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 4)
datSP %>% filter(!text %in% badwords)
datSP %>% filter(!text %in% badwords)%>%
select(text) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 4)
datSP %>% filter(!text %in% badwords)%>%
unnest_tokens(bigram, text, token = "ngrams", n = 4)
datSP %>% filter(!text %in% badwords)
datSP %>% filter(!text %in% badwords) %>%
select(text)
datSP %>% unnest_tokens(bigram, text, token = "ngrams", n = 1)
datSP <- readRDS("data/tweets_SP.rds")
datSP <- datSP %>%
filter(
location %in% c("São Paulo, Brasil","São Paulo", "Sao Paulo, Brazil", "Taubaté, São Paulo"
)
)
datSP <- datSP %>%
mutate(data = round_date(ymd_hms(created_at),"day"))
## networks
badwords <- stopwords::stopwords(language = "pt")
datSP %>% unnest_tokens(bigram, text, token = "ngrams", n = 1)
datSP %>% unnest_tokens(bigram, datSP$text, token = "ngrams", n = 1)
datSP
datSP <- readRDS("data/tweets_SP.rds")
datSP <- datSP %>%
filter(
location %in% c("São Paulo, Brasil","São Paulo", "Sao Paulo, Brazil", "Taubaté, São Paulo"
)
)
datSP <- datSP %>%
mutate(data = round_date(ymd_hms(created_at),"day"))
datSP
datSP
datSP %>% unnest_tokens(bigram, text, token = "ngrams", n = 1) %>%
anti_join(badwords)
datSP %>% filter(!is.na(text)) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 1) %>%
anti_join(badwords)
datSP %>% filter(!is.na(text)) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 1)
datSP <- readRDS("data/tweets_SP.rds")
datSP <- datSP %>%
filter(
location %in% c("São Paulo, Brasil","São Paulo", "Sao Paulo, Brazil", "Taubaté, São Paulo"
)
)
datSP <- datSP %>%
mutate(data = round_date(ymd_hms(created_at),"day"))
## networks
badwords <-  stopwords::stopwords(language = "pt")
datSP %>% filter(!is.na(text)) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 1)
datSP %>%   unnest_tokens(bigram, text, token = "ngrams", n = 1)
View(datSP)
datSP %>%   unnest_tokens(bigram, datSP$text, token = "ngrams", n = 1)
datSP %>%   unnest_tokens(bigram, datSP$text, token = "ngrams", n = 2)
datSP$text
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2)
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 1)
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2)
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
%>% count(bigram, sort = TRUE)
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE)
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE)%>%
separate(bigram, c("word1", "word2"), sep = " ")
## networks
badwords <-  stopwords::stopwords(language = "pt")
badwords <- c(badwords, "https","t.co")
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE)%>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% badwords) %>%
filter(!word2 %in% badwords)%>%
count(word1, word2, sort = TRUE)%>%
unite(bigram, word1, word2, sep = " ")
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE)%>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% badwords) %>%
filter(!word2 %in% badwords)%>%
count(word1, word2, sort = TRUE)%>%
unite(bigram, word1, word2, sep = " ") %>%
arrange(n) %>% tail(20)
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE)%>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% badwords) %>%
filter(!word2 %in% badwords)%>%
count(word1, word2, sort = TRUE)%>%
unite(bigram, word1, word2, sep = " ")
library(igraph)
install.packages("igraph")
library(igraph)
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE)%>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% badwords) %>%
filter(!word2 %in% badwords)%>%
count(word1, word2, sort = TRUE)%>%
unite(bigram, word1, word2, sep = " ")
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE)
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE) %>%
filter(n > 20) %>%
graph_from_data_frame()
install.packages("ggraph")
library(ggraph)
set.seed(2017)
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE) %>%
filter(n > 20) %>%
graph_from_data_frame()%>%
ggraph(layout = "fr") +
geom_edge_link() +
geom_node_point() +
geom_node_text(aes(label = name),
vjust = 1,
hjust = 1))
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE) %>%
filter(n > 20) %>%
graph_from_data_frame()%>%
ggraph(layout = "fr") +
geom_edge_link() +
geom_node_point() +
geom_node_text(aes(label = name),
vjust = 1,
hjust = 1)
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE) %>%
filter(n > 20) %>%
graph_from_data_frame()%>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE) %>%
filter(n > 20) %>%
graph_from_data_frame()%>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
datSP %>% select(text) %>%  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE) %>%
filter(n > 20) %>%
graph_from_data_frame()%>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = 0.5), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
library(stringr)
datSP %>%
count_bigrams()
count_bigrams <- function(dataset) {
dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE)
}
datSP %>%
count_bigrams()
datSP %>% select(text) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
count(bigram, sort = TRUE) %>%
filter(n > 20) %>%
graph_from_data_frame()%>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = 0.5), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
